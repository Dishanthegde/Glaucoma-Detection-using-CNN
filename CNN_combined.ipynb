{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "Sao7p-vQfGfw",
        "outputId": "b6076dbd-df1f-4e79-c41c-8037cf9935ce"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iw9rkDVM215N",
        "outputId": "46459d8e-09ee-47bb-87e7-1cb5d8c02abb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytVXKc_KfHTz"
      },
      "source": [
        "# Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDztaK8RaEOU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "from tensorflow import keras\n",
        "import seaborn as sns\n",
        "import random\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4izU3XdXrUS"
      },
      "source": [
        "# 1.Data collection & exploration\n",
        "\n",
        "The datasets used in the project were discovered and collected using the information from an open source eye disease database.Three datasets (Drishti Rim-One and Acrima datasets) had fundus photographies which present glaucoma.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WspCaneGaIKh"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "print(current_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH_-LQCCauhy"
      },
      "source": [
        "#1.1  DRISTHI\n",
        ">The dataset comprises of 101 retinal fundus images with 31 normal images and 70 glaucomatous images acquired using a retinal fundus camera. The ground truth for comparison of implemented approaches comprises of the ‘normal/abnormal’ labels and soft segmented maps of ‘disc/cup’ generated by the researchers of the IIIT Hyderabad in alliance with Aravind eye hospital in Madurai, India. It also includes a .txt file for each retinal image comprising of CDR values, which is a significant diagnostic parameter for glaucoma. Further, the images in the data repository are gathered from people of varying age groups visiting the hospital, with images acquired under varying brightness and contrast.\n",
        "Link to dataset: (https://cvit.iiit.ac.in/projects/mip/drishti-gs/mip-dataset2/Home.php)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSFsGnAHa5Le"
      },
      "outputs": [],
      "source": [
        "dristhi_dir = current_dir + '/drive/MyDrive/datasets/Dristhi/'\n",
        "train_glaucoma_dir = dristhi_dir + \"Training/Images/GLAUCOMA\"\n",
        "train_normal_dir = dristhi_dir + \"Training/Images/NORMAL\"\n",
        "test_glaucoma_dir = dristhi_dir + \"Test/Images/glaucoma\"\n",
        "test_normal_dir = dristhi_dir + \"Test/Images/normal\"\n",
        "dristhi_glaucoma_images = os.listdir(train_glaucoma_dir)+os.listdir(test_glaucoma_dir)\n",
        "dristhi_normal_images = os.listdir(train_normal_dir)+os.listdir(test_normal_dir)\n",
        "\n",
        "# Look at the number of samples in each dataset\n",
        "print(\"Dristhi dataset contains :\")\n",
        "print(f\"\\t{len(dristhi_glaucoma_images)} images representing an eye with glaucoma\")\n",
        "print(f\"\\t{len(dristhi_normal_images)} images representing a normal eye\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7OsXmOjUzsS"
      },
      "outputs": [],
      "source": [
        "print(\"Sample Dristhi glaucoma images:\")\n",
        "plt.subplots(figsize=(15, 10))\n",
        "for i in range(1, 5):\n",
        "    plt.subplot(1, 4, i)\n",
        "    plt.imshow(load_img(f\"{os.path.join(train_glaucoma_dir, dristhi_glaucoma_images[i - 1])}\"))\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nSample Dristhi normal images:\")\n",
        "plt.subplots(figsize=(15, 10))\n",
        "for i in range(1, 5):\n",
        "    plt.subplot(1, 4, i)\n",
        "    plt.imshow(load_img(f\"{os.path.join(train_normal_dir, dristhi_normal_images[i - 1])}\"))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNSzKZ4qayfi"
      },
      "source": [
        "# 1.2 Rim-One\n",
        "\n",
        ">The RIM-ONE DL image dataset consists of 313 retinographies from normal subjects and 172 retinographies from patients with glaucoma. These images were captured in three Spanish hospitals: Hospital Universitario de Canarias (HUC), in Tenerife, Hospital Universitario Miguel Servet (HUMS), in Zaragoza, and Hospital Clínico Universitario San Carlos (HCSC), in Madrid.\n",
        "\n",
        ">This dataset has been divided into training and test sets, with two variants:\n",
        "* Partitioned randomly: the training and test sets are built randomly from all the images of the dataset.\n",
        "* Partitioned by hospital: the images taken in the HUC are used for the training set, while the images taken in the HUMS and HCSC are used for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox3p_YDWdEZn"
      },
      "outputs": [],
      "source": [
        "rimOne_dir = current_dir + '/drive/MyDrive/datasets/RIM-ONE_DL_images/partitioned_randomly/'\n",
        "train_glaucoma_dir = rimOne_dir + \"training_set/glaucoma\"\n",
        "train_normal_dir = rimOne_dir + \"training_set/normal\"\n",
        "test_glaucoma_dir = rimOne_dir + \"test_set/glaucoma\"\n",
        "test_normal_dir = rimOne_dir + \"test_set/normal\"\n",
        "rimOne_glaucoma_images = os.listdir(train_glaucoma_dir)+os.listdir(test_glaucoma_dir)\n",
        "rimOne_normal_images = os.listdir(train_normal_dir)+os.listdir(test_normal_dir)\n",
        "\n",
        "# Look at the number of samples in each dataset\n",
        "print(\"Rim One dataset contains :\")\n",
        "print(f\"\\t{len(rimOne_glaucoma_images)} images representing an eye with glaucoma\")\n",
        "print(f\"\\t{len(rimOne_normal_images)} images representing a normal eye\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQA0YdXCW9p1"
      },
      "outputs": [],
      "source": [
        "print(\"Sample Rim-One glaucoma images:\")\n",
        "plt.subplots(figsize=(15, 10))\n",
        "for i in range(1, 5):\n",
        "    plt.subplot(1, 4, i)\n",
        "    plt.imshow(load_img(f\"{os.path.join(train_glaucoma_dir, rimOne_glaucoma_images[i - 1])}\"))\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nSample Rim-One normal images:\")\n",
        "plt.subplots(figsize=(15, 10))\n",
        "for i in range(1, 5):\n",
        "    plt.subplot(1, 4, i)\n",
        "    plt.imshow(load_img(f\"{os.path.join(train_normal_dir, rimOne_normal_images[i - 1])}\"))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_5rK0i9ag8h"
      },
      "source": [
        "# 1.3. ACRIMA dataset\n",
        "* Country: Spain\n",
        "* No. of patients: unknown\n",
        "* No. of images: 705\n",
        "* Diseases present: Glaucoma and healthy eyes\n",
        "* Instrument used: TRC retina camera (Topcon, Japan)\n",
        "* Image format: JPEG\n",
        "\n",
        ">ACRIMA database is composed by 705 fundus images (396 glaucomatous and 309 normal images). They were collected at the FISABIO Oftalmología Médica in Valencia, Spain, from glaucomatous and normal patients with their previous consent and in accordance with the ethical standards laid down in the 1964 Declaration of Helsinki. All images from ACRIMA database were annotated by glaucoma experts with several years of experience. They were cropped around the optic disc and renamed.\n",
        "\n",
        "\n",
        "\n",
        ">The image name has the following structure: First, the name starts with the two letters \"Im\", followed by an image number composed by three digits (starting from 001 until 705), followed by the label (this label is \"g\" if the image is pathological and \"_\" if the image is normal). Finally, all image names have the database name, \"ACRIMA\", at the end of their names. For example, a name for a glaucomatous image is \"Im686_g_ACRIMA\" and \"Im001_ACRIMA\" for a normal image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHzFtmffaLha"
      },
      "outputs": [],
      "source": [
        "acrima_dir = current_dir + \"/drive/MyDrive/datasets/acrima/Database\"\n",
        "glaucoma_dir = acrima_dir + \"/glaucoma\"\n",
        "normal_dir = acrima_dir + \"/normal\"\n",
        "\n",
        "normal_images = os.listdir(normal_dir)\n",
        "glaucoma_images = os.listdir(glaucoma_dir)\n",
        "\n",
        "# Look at the number of samples in each dataset\n",
        "print(\"Acrima dataset contains : \")\n",
        "print(f\"\\t{len(glaucoma_images)} images representing an eye with glaucoma\")\n",
        "print(f\"\\t{len(normal_images)} images representing a normal eye\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGDCGkfwaaoU"
      },
      "outputs": [],
      "source": [
        "print(\"Sample glaucoma images:\")\n",
        "plt.subplots(figsize=(15, 10))\n",
        "for i in range(1, 5):\n",
        "    plt.subplot(1, 4, i)\n",
        "    plt.imshow(load_img(f\"{os.path.join(glaucoma_dir, glaucoma_images[i - 1])}\"))\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nSample normal images:\")\n",
        "plt.subplots(figsize=(15, 10))\n",
        "for i in range(1, 5):\n",
        "    plt.subplot(1, 4, i)\n",
        "    plt.imshow(load_img(f\"{os.path.join(normal_dir, normal_images[i - 1])}\"))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3Fyr_QmF9jZ"
      },
      "source": [
        "Combining datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzwDdLT4_M2y"
      },
      "outputs": [],
      "source": [
        "os.mkdir('/content/combine')\n",
        "## define your paths for glaucoma####\n",
        "g_path1 = '/content/drive/MyDrive/datasets/acrima/Database/glaucoma'\n",
        "g_path2 = '/content/drive/MyDrive/datasets/RIM-ONE_DL_images/partitioned_randomly/training_set/glaucoma'\n",
        "g_path3 ='/content/drive/MyDrive/datasets/RIM-ONE_DL_images/partitioned_randomly/test_set/glaucoma'\n",
        "g_path4='/content/drive/MyDrive/datasets/Dristhi/Training/Images/GLAUCOMA'\n",
        "g_path5='/content/drive/MyDrive/datasets/Dristhi/Test/Images/glaucoma'\n",
        "g_dest='/content/drive/combine/glaucoma'\n",
        "\n",
        "os.mkdir(g_dest)\n",
        "g_list=[g_path1,g_path2,g_path3,g_path4,g_path5]\n",
        "\n",
        "for i in g_list:\n",
        "  shutil.copytree(i, g_dest, dirs_exist_ok=True)\n",
        "print(len(os.listdir('/content/drive/combine/glaucoma')))\n",
        "\n",
        "##################################################\n",
        "#normal\n",
        "n_path1='/content/drive/MyDrive/datasets/acrima/Database/normal'\n",
        "n_path2='/content/drive/MyDrive/datasets/RIM-ONE_DL_images/partitioned_randomly/training_set/normal'\n",
        "n_path3='/content/drive/MyDrive/datasets/RIM-ONE_DL_images/partitioned_randomly/test_set/normal'\n",
        "n_path4='/content/drive/MyDrive/datasets/Dristhi/Training/Images/NORMAL'\n",
        "n_path5='/content/drive/MyDrive/datasets/Dristhi/Test/Images/normal'\n",
        "n_dest='/content/combine/drive/normal'\n",
        "os.mkdir(n_dest)\n",
        "n_list=[n_path1,n_path2,n_path3,n_path4,n_path5]\n",
        "\n",
        "for i in n_list:\n",
        "  shutil.copytree(i,n_dest, dirs_exist_ok=True)\n",
        "print(len(os.listdir(n_dest)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDPfW_3Qa9w6"
      },
      "source": [
        "# Combined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhkgMqmObCIN"
      },
      "outputs": [],
      "source": [
        "base_dir = '/content/drive/MyDrive/datasets/combine'\n",
        "base_dir = pathlib.Path(base_dir)\n",
        "\n",
        "glaucoma = [fn for fn in os.listdir(f'/content/drive/MyDrive/datasets/combine/glaucoma/')]\n",
        "normal = [fn for fn in os.listdir(f'/content/drive/MyDrive/datasets/combine/normal')]\n",
        "data=[glaucoma,normal]\n",
        "dataset_classes =['glaucoma','normal']\n",
        "\n",
        "image_count = len(list(base_dir.glob('*/*.jpg')))+len(list(base_dir.glob('*/*.png')))\n",
        "print(f'Total images: {image_count}')\n",
        "print(f'Total number of classes: {len(dataset_classes)}')\n",
        "count = 0\n",
        "data_count = []\n",
        "for x in dataset_classes:\n",
        "  print(f'Total {x} images: {len(data[count])}')\n",
        "  data_count.append(len(data[count]))\n",
        "  count += 1\n",
        "\n",
        "sns.set_style('darkgrid')\n",
        "sns.barplot(x=dataset_classes, y=data_count)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KBQcx1KdLFX"
      },
      "source": [
        "Spliiting Ratio of Dataset 80:10:10 (Train:Test:Validation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFnPfRFiC-Zm"
      },
      "outputs": [],
      "source": [
        "!pip install split-folders\n",
        "import splitfolders #to split dataset\n",
        "import pathlib\n",
        "base_ds = '/content/drive/MyDrive/datasets/combine'\n",
        "base_ds = pathlib.Path(base_ds)\n",
        "img_height=256\n",
        "img_width=256\n",
        "batch_size=32\n",
        "splitfolders.ratio(base_ds, output='images', seed=1321, ratio=(.8,.1,.1), group_prefix=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eHt2pNNc9Ks"
      },
      "source": [
        "Data augmentation done using Image Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnFbVwUPAX0D"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(rescale=1./255,\n",
        "shear_range = 0.15,\n",
        "zoom_range = 0.15,\n",
        "horizontal_flip = True)\n",
        "train_ds = datagen.flow_from_directory(\n",
        "    'images/train',\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False)\n",
        "\n",
        "val_ds = datagen.flow_from_directory(\n",
        "    'images/val',\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False)\n",
        "\n",
        "test_ds = datagen.flow_from_directory(\n",
        "    'images/test',\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmhVrKtBtmZf"
      },
      "source": [
        "## CNN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZe5QJGFdOga"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense,Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "# Initialising the CNN\n",
        "classifier = Sequential()\n",
        "# Step 1 - Adding Convolution layer\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape = (256,256, 3), activation = 'relu'))\n",
        "\n",
        "# Step 2 - Adding MaxPooling layers\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "# Adding a second convolutional layer\n",
        "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Step 3 - Flattening\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Step 4 - Full connection\n",
        "classifier.add(Dense(units = 512, activation = 'relu'))\n",
        "classifier.add(BatchNormalization()),\n",
        "classifier.add(Dense(256,activation='relu')),\n",
        "classifier.add(Dropout(0.25)),\n",
        "classifier.add(Dense(units = 2, activation = 'softmax'))\n",
        "\n",
        "# Compiling the CNN\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_EQBP16Olqt"
      },
      "outputs": [],
      "source": [
        "classifier.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwTa7q1kgNkN"
      },
      "outputs": [],
      "source": [
        "model_info=classifier.fit(train_ds,\n",
        "steps_per_epoch = int(round(1032/32)),\n",
        "epochs = 150,\n",
        "validation_data = val_ds,\n",
        "validation_steps = int(round(128/32)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRkx23BggZyL"
      },
      "outputs": [],
      "source": [
        "classifier.save('/content/drive/MyDrive/datasets/combine_model/combine_cnn.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WggNfCr2BOju"
      },
      "outputs": [],
      "source": [
        "def plot_train_history(history):\n",
        "    plt.figure(figsize=(15,5))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "plot_train_history(model_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uldXeqWoFXyf"
      },
      "source": [
        "Loading Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZRyzKUbikeK"
      },
      "outputs": [],
      "source": [
        "model=load_model('/content/drive/MyDrive/datasets/combine_model/combine_cnn.h5')\n",
        "print(\"Glaucoma detection model loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LS939u-B0G9U"
      },
      "outputs": [],
      "source": [
        "def glaucoma_prediction(test_image):\n",
        "  image = img_to_array(test_image)\n",
        "  image = np.expand_dims(image, axis = 0)\n",
        "  result = np.argmax(model.predict(image))\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HN8xCdNZjDEG"
      },
      "outputs": [],
      "source": [
        "test_image = load_img('/content/drive/MyDrive/datasets/acrima/Database/glaucoma/Im310_g_ACRIMA.jpg', target_size = (256,256))\n",
        "prediction = glaucoma_prediction(test_image)\n",
        "if prediction == 0:\n",
        " print(\"Glaucoma\")\n",
        "else:\n",
        " print(\"Not Glaucoma\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvaEInjPeVOv"
      },
      "outputs": [],
      "source": [
        "test_image = load_img('/content/drive/MyDrive//datasets/acrima/Database/normal/Im001_ACRIMA.jpg', target_size = (256,256))\n",
        "prediction = glaucoma_prediction(test_image)\n",
        "if prediction == 0:\n",
        " print(\"Glaucoma\")\n",
        "else:\n",
        " print(\"Not Glaucoma\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxcTRmByVSXT"
      },
      "source": [
        "# Model Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRiq32yKbTuT"
      },
      "outputs": [],
      "source": [
        "score=model.evaluate(test_ds)\n",
        "print(\"Loss:\",score[0],\"Accuracy:\",score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqLUPNMQR7IF"
      },
      "source": [
        "Testing set confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXD1tBkfJPYG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "import seaborn as sb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uO3wvhZhJk7i"
      },
      "outputs": [],
      "source": [
        "pred= np.round(model.predict(test_ds, verbose=1))\n",
        "test_labels=test_ds.labels\n",
        "test_pred_labels=[]\n",
        "for i in range(len(pred)):\n",
        "  test_pred_labels.append(np.argmax(pred[i]))\n",
        "conf_matrix= confusion_matrix(test_pred_labels,test_labels)\n",
        "print (conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5HrHtJ0I0zU"
      },
      "outputs": [],
      "source": [
        "sb.heatmap(conf_matrix,cmap='Purples', annot=True,xticklabels=['glaucoma','normal'],yticklabels=['glaucoma','normal'],linewidths=1,\n",
        "                linecolor='green').plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKveafK4IxyR"
      },
      "outputs": [],
      "source": [
        "test_report = classification_report(test_ds.labels,test_pred_labels, target_names=['glaucoma','normal'], output_dict=True)\n",
        "test_df = pd.DataFrame(test_report).transpose()\n",
        "test_df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "G4izU3XdXrUS",
        "aH_-LQCCauhy",
        "GNSzKZ4qayfi",
        "Y_5rK0i9ag8h",
        "pDPfW_3Qa9w6",
        "TmhVrKtBtmZf"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}